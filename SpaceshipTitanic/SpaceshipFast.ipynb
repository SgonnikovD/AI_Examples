{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fedfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastcore.all import *\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edad5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/spaceship-titanic-train.csv')\n",
    "test_df  = pd.read_csv('./data/spaceship-titanic-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da483b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "targ = 'Transported'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a6d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a31520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование столбцов: категоризация (Label encoding), заполнение пропусков, нормализация\n",
    "procs=[Categorify, FillMissing, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8812f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predproduction(data):\n",
    "    \"\"\"Редактирует входной DataFrame в части\n",
    "    заполнения пропусков, определения количества людей с одинаковой фамилией,\n",
    "    людей из одной группы (по номерам билетов),\n",
    "    обрабатывает категориальные признаки по принципу One-Hot Encoding\n",
    "    Возвращает отредактированный DataFrame\n",
    "    \"\"\"\n",
    "    object_cols = data.columns[data.dtypes == 'object']\n",
    "    num_cols =    data.columns[data.dtypes == 'float64']\n",
    "    for col in object_cols:\n",
    "        data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "    for col in num_cols:\n",
    "        data[col].fillna(data[col].median(), inplace=True)\n",
    "    \n",
    "    fams = data['Name'].str.split(expand=True)[1]\n",
    "    fam_counts = fams.value_counts()\n",
    "    data['FamilySize'] = fams.apply(lambda x: fam_counts[x].astype('int'))\n",
    "    data=data.drop('Name', axis=1)\n",
    "\n",
    "    groups = data['PassengerId'].str.split('_', expand=True)[0]\n",
    "    group_counts = groups.value_counts()\n",
    "    data['GroupSize'] = groups.apply(lambda x: group_counts[x]).astype('int')\n",
    "    data=data.drop('PassengerId', axis=1)\n",
    "    \n",
    "    data['CryoSleep'] = data['CryoSleep'].astype('int')\n",
    "    data['VIP'] = data['VIP'].astype('int')\n",
    "    data = data.drop('VIP',axis=1)\n",
    "    \n",
    "    data['Deck']=data['Cabin'].str.split('/', expand=True)[0]\n",
    "    data['Side']=data['Cabin'].str.split('/', expand=True)[2]\n",
    "    data=data.drop('Cabin', axis=1)\n",
    "    \n",
    "    data = pd.concat(\n",
    "        [\n",
    "            data,\n",
    "            pd.get_dummies(data[\"HomePlanet\"], prefix=\"HomePlanet\"),\n",
    "            pd.get_dummies(data[\"Destination\"], prefix=\"Destination\"),\n",
    "            pd.get_dummies(data[\"Deck\"], prefix=\"Deck\"),\n",
    "            pd.get_dummies(data[\"Side\"], prefix=\"Side\")\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    data = data.drop('HomePlanet',axis=1)\n",
    "    data = data.drop('Destination',axis=1)\n",
    "    data = data.drop('Deck',axis=1)\n",
    "    data = data.drop('Side',axis=1)\n",
    "    \n",
    "    data['Wastes'] = data[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
    "   \n",
    "    return data\n",
    "    del_cols = ['Name', 'PassengerId', 'Cabin']\n",
    "    for col in del_cols:\n",
    "        data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "    \n",
    "    fams = data['Name'].str.split(expand=True)[1]\n",
    "    fam_counts = fams.value_counts()\n",
    "    data['FamilySize'] = fams.apply(lambda x: fam_counts[x].astype('int'))\n",
    "    data=data.drop('Name', axis=1)\n",
    "    \n",
    "    groups = data['PassengerId'].str.split('_', expand=True)[0]\n",
    "    group_counts = groups.value_counts()\n",
    "    data['GroupSize'] = groups.apply(lambda x: group_counts[x]).astype('int')\n",
    "    data=data.drop('PassengerId', axis=1)\n",
    "    \n",
    "    data['Deck']=data['Cabin'].str.split('/', expand=True)[0]\n",
    "    data['Side']=data['Cabin'].str.split('/', expand=True)[2]\n",
    "    data=data.drop('Cabin', axis=1)\n",
    "    \n",
    "    data['Wastes'] = data[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
    "    \n",
    "    object_cols = list(data.columns[data.dtypes == 'object'])\n",
    "    num_cols =    list(data.columns[data.dtypes == 'float64']) + ['GroupSize', 'FamilySize']\n",
    "\n",
    "    return (data, object_cols, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d5b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, cat_cols, con_cols = predproduction(train_df.copy())\n",
    "test_data, _, _ = predproduction(test_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e390cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Деление выборки на обучающую и валидационную\n",
    "split_num = int(np.floor(0.3 * train_df.shape[0]))\n",
    "indices = list(range(train_df.shape[0]))\n",
    "np.random.seed()\n",
    "np.random.shuffle(indices)\n",
    "valid_idx, train_idx = indices[:split_num], indices[split_num:]\n",
    "splits=(list(train_idx), list(valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ae751",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b678cc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8360cb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = TabularDataLoaders.from_df(train_data, procs=procs, cat_names=cat_cols,cont_names=con_cols,\n",
    "                                 y_names=targ, valid_idx=list(valid_idx), bs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1521d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, layers=[500,250], metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aab7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поиск оптимальной скорости обучения\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7a701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6820bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = learn.dls.test_dl(test_data)\n",
    "_, _, label = learn.get_preds(dl=test_dl, with_decoded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0870bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, passid, out_file,\n",
    "                             target='Transported', index_label=\"PassengerId\"):\n",
    "    \"\"\"Переводит предсказания модели в DataFrame и сохранение в csv-файл\"\"\"\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                passid,\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09953a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_submission_file(np.array(label).astype('bool'), test_df['PassengerId'], 'spacetitanic_pred_fai.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
